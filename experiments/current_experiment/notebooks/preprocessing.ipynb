{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading image dataset and CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas\n",
    "import numpy \n",
    "from augmentations import augmentations\n",
    "from datasets import datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "images = []\n",
    "\n",
    "for fil in os.listdir(\"../data/raw_data/images\"):\n",
    "    file_dir = os.path.join(\"../data/raw/data/images\", fil)\n",
    "    images.append(file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset information CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loader = numpy.vectorize(pyfunc=lambda img: Image.open(img))\n",
    "\n",
    "train_info = pandas.read_csv(\"../data/raw_data/information.csv\")\n",
    "train_info['image'] = image_loader(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info['Class'].map({\n",
    "    'yes': 0,\n",
    "    'no': 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting images to specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_png(img):\n",
    "    success, png_data = cv2.imencode(ext='.png', img=img)\n",
    "    if success:\n",
    "        png_img = cv2.imdecode(png_data, cv2.IMREAD_UNCHANGED)\n",
    "        return Image.fromarray(png_img)\n",
    "    else:\n",
    "        raise RuntimeError('Failed to convert image')\n",
    "\n",
    "train_info['image'] = train_info['image'].apply(lambda img: to_png(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring noise degree by using TV (Total Variation), \n",
    "SNR (Signal-to-Noise Ratio) and NLE (Noise Local Estimation) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import estimate_sigma, denoise_tv_chambolle\n",
    "\n",
    "def total_variation(image):\n",
    "    dx = numpy.diff(image, axis=1)\n",
    "    dy = numpy.diff(image, axis=0)\n",
    "    tv = numpy.sum(numpy.abs(dx)) + numpy.sum(numpy.abs(dy))\n",
    "    return tv\n",
    "\n",
    "def noise_local_estimation(img, weight):\n",
    "    if gray_img.shape[0] == 3:\n",
    "        gray_img = cv2.cvtColor(gray_img, cv2.COLOR_RGB2GRAY)\n",
    "    tv_img = estimate_sigma(gray_img)\n",
    "    tv = numpy.sum(numpy.abs(tv_img - gray_img))\n",
    "    return tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_info['image'].tolist()\n",
    "\n",
    "tv_thresh = 10 \n",
    "snr_thresh = 100\n",
    "nle_thresh = 200\n",
    "\n",
    "for image in images:\n",
    "    tv = total_variation(image)\n",
    "    snr = signal_to_noise_ratio(image)\n",
    "    nle = noise_local_estimation(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Datasets for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    numpy.arrange(train_info.shape[0]), \n",
    "    test_size=0.3, \n",
    "    stratify=train_info['class'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.DeepFakeClassificationDataset(\n",
    "    labels=train_info['class'][train_indices],\n",
    "    images=train_info['image'][train_indices],\n",
    "    transforms=augmentations.get_training_augmentations()\n",
    ")\n",
    "\n",
    "validation_dataset = datasets.DeepFakeClassificationDataset(\n",
    "    labels=train_info['class'][val_indices],\n",
    "    images=train_info['image'][val_indices],\n",
    "    transforms=augmentations.get_validation_augmentations()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing image quality estimation using SNR and SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling disbalance in the dataset using Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGHTS = [1, 1]\n",
    "\n",
    "train_dataset.weights = validation_dataset.weights = CLASS_WEIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving datasets to local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(obj=train_dataset, file=open(\"../data/augmented_data/train_dataset.pkl\", mode='wb'))\n",
    "pickle.dump(obj=validation_dataset, file=open(\"../data/augmented_data/validation_dataset.pkl\", mode='wb'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
