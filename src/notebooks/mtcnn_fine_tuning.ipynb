{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f305666-4a1b-422c-b65a-14eb1c225828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e119a0eb-be29-4e26-a3e6-fcb818854a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7707ff-9a9d-480a-b7e5-1baed346536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee28532c-85da-445e-a0c5-45237e014448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import json\n",
    "import pandas\n",
    "import typing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b87fa01-5c54-49d5-b490-abda03bc00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.losses import losses\n",
    "from src.training.metrics import metrics as eval_metrics\n",
    "from src.training.trainers import regularization\n",
    "from src.preprocessing import augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b30eaba-404d-4e16-b08f-72836e6a5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"../experiments/experiment1/data/train_data\"\n",
    "TRAIN_ANNOTATIONS = \"../experiments/experiment1/labels/train_labels\"\n",
    "VALIDATION_DIR = \"../experiments/experiment1/data/validation_data\"\n",
    "VALIDATION_ANNOTATIONS = \"../experiments/experiment1/labels/validation_labels\"\n",
    "DATA_CONFIG_DIR = \"../experiments/experiment1/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4b2d40-ff7d-40d8-bf5a-0005a8e18816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLAnnotationParser(object):\n",
    "    \"\"\"\n",
    "    Class for extracting annotations\n",
    "    from .xml files.\n",
    "    \"\"\"\n",
    "    def parse_annotations(self, input_path: str) -> pandas.DataFrame:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c7752d-cb31-45bb-85e9-a2f6dca7873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml_annotations(annotations_path: str) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads xml annotations from the specified \n",
    "    'annotations_path' directory folder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        annotations_path - path, containing xml annotations for data\n",
    "    \"\"\"\n",
    "    parser = XMLAnnotationParser()\n",
    "    output_anns = None \n",
    "    \n",
    "    for path in glob(pathname=\"**/*.%s\" % file_ext, root_dir=annotations_path):\n",
    "        ann_path = os.path.join(annotations_path, path)\n",
    "        \n",
    "        annotations = parser.parse_annotations(ann_path)\n",
    "        if output_anns is None:\n",
    "            output_anns = annotations\n",
    "        else:\n",
    "            output_anns = pandas.concat([output_anns, annotations], axis=0)\n",
    "    return output_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef2882c-89e3-42db-8a77-9a9b5c67d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(root_dir: str, file_extensions: typing.List):\n",
    "    output_images = []\n",
    "    \n",
    "    for ext in file_extensions:\n",
    "        found_images = glob(pathname=\"**/*.%s\" % ext, root_dir=root_dir)\n",
    "        output_images.extend(found_images)\n",
    "        \n",
    "    return output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94feb72-c38a-47d8-b602-a6703cb8b7e9",
   "metadata": {},
   "source": [
    "# Loading annotations for training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65a5309-293e-4e74-bd91-dac6b7a670df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = load_xml_annotations(TRAIN_ANNOTATIONS)\n",
    "validation_annotations = load_xml_annotations(VALIDATION_ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba957427-8897-486b-8662-08b9f71acc43",
   "metadata": {},
   "source": [
    "# Loading image train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda729a-8470-497d-abe1-972ac33b5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_image_data(TRAIN_DATASET_DIR, [\"jpeg\", \"png\", \"jpg\"])\n",
    "validation_dataset = load_image_data(VALIDATION_DATASET_DIR, [\"jpeg\", \"png\", \"jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbcf932-83db-46c1-be9f-16b4f3e1c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hashes = []\n",
    "train_annotations.set_index(\"video_name\")\n",
    "sorted_train_annotations = train_annotations.reindex(train_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df91ea-1dc2-4c34-b658-589c31aa5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_hashes = []\n",
    "validation_annotations.set_index(\"video_name\")\n",
    "sorted_validation_annotations = validation_annotations.reindex(validation_hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9ba81-f972-458f-8e10-1485022e6656",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33601b92-d6a8-42c0-a9b7-48b14b9176d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_augmentations = albumentations.Compose(\n",
    "    transforms=[\n",
    "        albumentations.ImageCompression(compression_type=0, quality_upper=100, quality_lower=60),\n",
    "        albumentations.GaussianNoise(p=0.05),\n",
    "        albumentations.GaussianBlur(p=0.1),\n",
    "        albumentations.RandomGamma(p=0.5),\n",
    "        albumentations.OneOf([\n",
    "            resize.IsoptropicResize(\n",
    "                MTCNN_IMAGE_SIZE, \n",
    "                interpolation_up=cv2.INTER_LINEAR, \n",
    "                interpolation_down=cv2.INTER_NEAREST\n",
    "            ),\n",
    "            resize.IsotropicResize(\n",
    "                MTCNN_IMAGE_SIZE, \n",
    "                interpolation_up=cv2.INTER_CUBIC, \n",
    "                interpolation_down=cv2.INTER_LINEAR\n",
    "            ),\n",
    "            resize.IsotropicResize(\n",
    "                MTCNN_IMAGE_SIZE,\n",
    "                interpolation_up=cv2.INTER_NEAREST,\n",
    "                interpolation_down=cv2.INTER_LINEAR\n",
    "            ),\n",
    "        ]),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.OneOf(\n",
    "            transforms=[\n",
    "                albumentations.RandomBrightnessContrast(\n",
    "                    \n",
    "                ),\n",
    "                albumentations.FancyPCA(),\n",
    "                albumentations.HueSaturationValue(),\n",
    "            ]\n",
    "        )\n",
    "        albumentations.ShiftScaleRotate(\n",
    "            rotation_limit=0,\n",
    "            scale_limit=0.2,\n",
    "            shift_limit=1,\n",
    "            border_mode=cv2.BORDER_CONSTANT\n",
    "        )\n",
    "    ], bbox_params=albumentations.BboxParams(\n",
    "        format='pascal_voc', \n",
    "        label_fields=[\"bbox_labels\"] # when calling 'transforms()' \n",
    "        # you need to pass bounding box labels, under `bbox_labels`\n",
    "    )\n",
    ")\n",
    "\n",
    "validation_augmentations = albumentations.Compose(\n",
    "    transforms=[\n",
    "        albumentations.OneOf([\n",
    "            resize.IsoptropicResize(\n",
    "                MTCNN_IMAGE_SIZE, \n",
    "                interpolation_up=cv2.INTER_LINEAR, \n",
    "                interpolation_down=cv2.INTER_NEAREST\n",
    "            ),\n",
    "            resize.IsotropicResize(\n",
    "                MTCNN_IMAGE_SIZE, \n",
    "                interpolation_up=cv2.INTER_CUBIC, \n",
    "                interpolation_down=cv2.INTER_LINEAR\n",
    "            ),\n",
    "            resize.IsotropicResize(\n",
    "                MTCNN_IMAGE_SIZE,\n",
    "                interpolation_up=cv2.INTER_NEAREST,\n",
    "                interpolation_down=cv2.INTER_LINEAR\n",
    "            ),\n",
    "        ]),\n",
    "        albumentations.HorizontalFlip(p=0.5)\n",
    "    ], bbox_params=albumentations.BboxParams(\n",
    "        format='pascal_voc', \n",
    "        label_fields=['bbox_classes']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553da62-c2dd-40db-8686-69dc07c8eb57",
   "metadata": {},
   "source": [
    "# Initializing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76732b55-99d5-4120-8ff0-a28f7419c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = datasets.MTCNNFineTuneDataset(\n",
    "    image_paths=train_dataset,\n",
    "    boxes=sorted_train_annotations['boxes'].tolist(),\n",
    "    transformations=train_augmentations\n",
    ")\n",
    "\n",
    "validation_dataset = datasets.MTCNNFineTuneDataset(\n",
    "    image_paths=validation_dataset,\n",
    "    boxes=sorted_validation_annotations['boxes'].tolist(),\n",
    "    transformations=validation_augmentations\n",
    ")\n",
    "\n",
    "early_stop_dataset = datasets.MTCNNFineTuneDataset(\n",
    "    image_paths=early_dataset,\n",
    "    boxes=early_annotations['boxes'].tolist(),\n",
    "    transformations=validation_augmentations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d10c0-e54a-4092-b50a-123a2d8da74c",
   "metadata": {},
   "source": [
    "# Initializing configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc1b9c4-6f18-41b5-b50d-1fa7230cc1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.02\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# early stopping patience\n",
    "\n",
    "early_patience = 5\n",
    "min_diff = 0.05\n",
    "early_start = 2\n",
    "early_stopper = regularization.EarlyStopping(early_patience, min_diff)\n",
    "\n",
    "# initialization data loaders\n",
    "\n",
    "workers_per_loader = max(os.cpu_count()-1, 0) // 3 # for train, val and early loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "074e4a83-ffdb-4e48-aec7-f6ef682214e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval metric and loss function for fine-tuning\n",
    "loss_function = losses.CIOULoss()\n",
    "eval_metric = eval_metrics.IOUScore()\n",
    "\n",
    "# network, optimizer and LR Scheduling techniques\n",
    "\n",
    "network = MTCNN(\n",
    "    min_face_size=160, \n",
    "    margin=10, \n",
    "    post_process=False, \n",
    "    thresholds=[0.8, 0.9, 0.95],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    network.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "scheduler = lr_scheduler.MultiStepLR(\n",
    "    optimizer, \n",
    "    [5, 10, 15, 20], \n",
    "    gamma=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b875f92-82ac-4d5b-9891-f70bd7d0dd5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=workers_per_loader,\n",
    "    batch_size=train_batch_size\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    batch_size=1,\n",
    "    dataset=validation_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=workers_per_loader\n",
    ")\n",
    "\n",
    "early_loader = data.DataLoader(\n",
    "    batch_size=1,\n",
    "    dataset=early_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=workers_per_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02318a0e-e442-435b-8dc2-04deeae0d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_architecture(model):\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        print(\"Module name: \", name)\n",
    "        print(\"Module type: \", type(module))\n",
    "        if hasattr(module, '_modules'):\n",
    "            print(\"Submodules: \", module._modules)\n",
    "\n",
    "def print_model_layers(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print('param name: %s' % name)\n",
    "        print('param type: %s' % type(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56216d66-78d5-46f6-a413-c6c463e3a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module name:  \n",
      "Module type:  <class 'facenet_pytorch.models.mtcnn.MTCNN'>\n",
      "Submodules:  OrderedDict([('pnet', PNet(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu1): PReLU(num_parameters=10)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=16)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu3): PReLU(num_parameters=32)\n",
      "  (conv4_1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (softmax4_1): Softmax(dim=1)\n",
      "  (conv4_2): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")), ('rnet', RNet(\n",
      "  (conv1): Conv2d(3, 28, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu1): PReLU(num_parameters=28)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): Conv2d(28, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=48)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv3): Conv2d(48, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (prelu3): PReLU(num_parameters=64)\n",
      "  (dense4): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (prelu4): PReLU(num_parameters=128)\n",
      "  (dense5_1): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (softmax5_1): Softmax(dim=1)\n",
      "  (dense5_2): Linear(in_features=128, out_features=4, bias=True)\n",
      ")), ('onet', ONet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu1): PReLU(num_parameters=32)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=64)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (prelu3): PReLU(num_parameters=64)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (prelu4): PReLU(num_parameters=128)\n",
      "  (dense5): Linear(in_features=1152, out_features=256, bias=True)\n",
      "  (prelu5): PReLU(num_parameters=256)\n",
      "  (dense6_1): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (softmax6_1): Softmax(dim=1)\n",
      "  (dense6_2): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (dense6_3): Linear(in_features=256, out_features=10, bias=True)\n",
      "))])\n",
      "Module name:  pnet\n",
      "Module type:  <class 'facenet_pytorch.models.mtcnn.PNet'>\n",
      "Submodules:  OrderedDict([('conv1', Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))), ('prelu1', PReLU(num_parameters=10)), ('pool1', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv2', Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1))), ('prelu2', PReLU(num_parameters=16)), ('conv3', Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))), ('prelu3', PReLU(num_parameters=32)), ('conv4_1', Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))), ('softmax4_1', Softmax(dim=1)), ('conv4_2', Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1)))])\n",
      "Module name:  pnet.conv1\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.prelu1\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.pool1\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.conv2\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.prelu2\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.conv3\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.prelu3\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.conv4_1\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.softmax4_1\n",
      "Module type:  <class 'torch.nn.modules.activation.Softmax'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  pnet.conv4_2\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet\n",
      "Module type:  <class 'facenet_pytorch.models.mtcnn.RNet'>\n",
      "Submodules:  OrderedDict([('conv1', Conv2d(3, 28, kernel_size=(3, 3), stride=(1, 1))), ('prelu1', PReLU(num_parameters=28)), ('pool1', MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv2', Conv2d(28, 48, kernel_size=(3, 3), stride=(1, 1))), ('prelu2', PReLU(num_parameters=48)), ('pool2', MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv3', Conv2d(48, 64, kernel_size=(2, 2), stride=(1, 1))), ('prelu3', PReLU(num_parameters=64)), ('dense4', Linear(in_features=576, out_features=128, bias=True)), ('prelu4', PReLU(num_parameters=128)), ('dense5_1', Linear(in_features=128, out_features=2, bias=True)), ('softmax5_1', Softmax(dim=1)), ('dense5_2', Linear(in_features=128, out_features=4, bias=True))])\n",
      "Module name:  rnet.conv1\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.prelu1\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.pool1\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.conv2\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.prelu2\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.pool2\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.conv3\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.prelu3\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.dense4\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.prelu4\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.dense5_1\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.softmax5_1\n",
      "Module type:  <class 'torch.nn.modules.activation.Softmax'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  rnet.dense5_2\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet\n",
      "Module type:  <class 'facenet_pytorch.models.mtcnn.ONet'>\n",
      "Submodules:  OrderedDict([('conv1', Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))), ('prelu1', PReLU(num_parameters=32)), ('pool1', MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv2', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))), ('prelu2', PReLU(num_parameters=64)), ('pool2', MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv3', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))), ('prelu3', PReLU(num_parameters=64)), ('pool3', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)), ('conv4', Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))), ('prelu4', PReLU(num_parameters=128)), ('dense5', Linear(in_features=1152, out_features=256, bias=True)), ('prelu5', PReLU(num_parameters=256)), ('dense6_1', Linear(in_features=256, out_features=2, bias=True)), ('softmax6_1', Softmax(dim=1)), ('dense6_2', Linear(in_features=256, out_features=4, bias=True)), ('dense6_3', Linear(in_features=256, out_features=10, bias=True))])\n",
      "Module name:  onet.conv1\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.prelu1\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.pool1\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.conv2\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.prelu2\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.pool2\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.conv3\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.prelu3\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.pool3\n",
      "Module type:  <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.conv4\n",
      "Module type:  <class 'torch.nn.modules.conv.Conv2d'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.prelu4\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.dense5\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.prelu5\n",
      "Module type:  <class 'torch.nn.modules.activation.PReLU'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.dense6_1\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.softmax6_1\n",
      "Module type:  <class 'torch.nn.modules.activation.Softmax'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.dense6_2\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n",
      "Module name:  onet.dense6_3\n",
      "Module type:  <class 'torch.nn.modules.linear.Linear'>\n",
      "Submodules:  OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print_model_architecture(MTCNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c7f1a54-c55f-4e1f-90f8-387e5d22a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param name: pnet.conv1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.prelu1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.prelu2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv3.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.prelu3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv4_1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv4_1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv4_2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: pnet.conv4_2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.prelu1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.prelu2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.conv3.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.prelu3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense4.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense4.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.prelu4.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense5_1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense5_1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense5_2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: rnet.dense5_2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.prelu1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.prelu2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv3.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.prelu3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv4.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.conv4.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.prelu4.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense5.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense5.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.prelu5.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_1.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_1.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_2.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_2.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_3.weight\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n",
      "param name: onet.dense6_3.bias\n",
      "param type: <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "print_model_layers(MTCNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a0c9254-6bae-4d73-bed2-2f6cda6e89bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59 µs, sys: 20 µs, total: 79 µs\n",
      "Wall time: 68.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class TunePipeline(object):\n",
    "    \"\"\"\n",
    "    Training pipeline for tuning\n",
    "    MTCNN face detector\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        network: nn.Module,\n",
    "        loss_function: nn.Module,\n",
    "        eval_metric: nn.Module,\n",
    "        max_epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer: nn.Module,\n",
    "        lr_scheduler: nn.Module,\n",
    "        snapshot_path: str,\n",
    "        inf_device\n",
    "    ):\n",
    "        self.network = network.to(device)\n",
    "        self.loss_function = loss_function\n",
    "        self.eval_metric = eval_metric\n",
    "        self.max_epochs: int = max_epochs\n",
    "        self.batch_size: int = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.snapshot_path = snapshot_path\n",
    "        self.inf_device = inf_device\n",
    "        self.freeze_mtcnn_layers()\n",
    "\n",
    "    def freeze_mtcnn_layers(self, layers: typing.Dict[str, int]):\n",
    "        \"\"\"\n",
    "        Freezes layers of MTCNN face detector\n",
    "        Parameters:\n",
    "        ----------\n",
    "            layers - (typing.Dict) - dict structure: {\"block_name\": \"layer_name\"}\n",
    "            Example:\n",
    "                layers = {\"onet\": \"conv1\", \"rnet\": \"dense3\"}\n",
    "        \"\"\"\n",
    "        for name, param in self.network.named_parameters():\n",
    "            if name[:4].lower() not in layers:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                layer_name = name[4:].split(\".\")[0]\n",
    "                if layer_name in layers.values():\n",
    "                    param.requires_grad = False\n",
    "                else:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    def save_checkpoint(self, epoch: int, loss: float):\n",
    "        \n",
    "        snapshot_full_path = os.path.join(\n",
    "            self.snapshot_path, \n",
    "            \"model_epoch_%s.pth\" % epoch\n",
    "        )\n",
    "        \n",
    "        snapshot = {\n",
    "            'model_state': self.network.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'lr_scheduler_state': self.lr_scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(\n",
    "            obj=snapshot, \n",
    "            f=snapshot_full_path\n",
    "        )\n",
    "\n",
    "    def train(self, loader: data.DataLoader):\n",
    "        \"\"\"\n",
    "        Runs fine-tuning process\n",
    "        of MTCNN detector.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        loader - data loader, containing train dataset\n",
    "\n",
    "        Returns:\n",
    "            - train_loss - (float) value, representing\n",
    "            the best loss across all executed epochs\n",
    "        \"\"\"\n",
    "        self.network.train()\n",
    "        train_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.max_epochs):\n",
    "            \n",
    "            epoch_loss = []\n",
    "            for images, boxes in loader:\n",
    "                \n",
    "                predictions = self.network.detect_faces()\n",
    "                pred_boxes, act_boxes = self.match_boxes(predictions, boxes)\n",
    "                \n",
    "                loss = self.loss_function(pred_boxes, act_boxes)\n",
    "                loss.backward()\n",
    "                \n",
    "                epoch_loss.append(loss.item())\n",
    "                \n",
    "            train_loss = min(train_loss, numpy.mean(epoch_loss))\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            if epoch % self.save_eer\n",
    "        return train_loss\n",
    "        \n",
    "    def evaluate(self, loader: data.DataLoader):\n",
    "        \n",
    "        eval_metric = 0\n",
    "        with torch.no_grad():\n",
    "            for image, boxes in loader:\n",
    "                pass\n",
    "        return eval_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92323e-675f-4589-a2a4-1357671d6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer = TuningPipeline(\n",
    "    network=network,\n",
    "    loss_function=loss_function,\n",
    "    eval_metric=eval_metric,\n",
    "    max_epochs=max_epochs,\n",
    "    early_stopper=early_stopper,\n",
    "    early_dataset=early_dataset,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c7f20-1d56-4513-b40a-87a4ba486ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = trainer.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2f269-7cc0-440e-9f0e-ad110715ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loss on fine tuning dataset: %s ' % train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db8761-f03b-4b52-9a05-24f8fec1f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = trainer.evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfea3cd-01f2-4cab-8cab-c9e7ffab09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('evaluation metric on validation dataset: %s ' % eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d973578-c506-4473-96d7-4ffaf0208edb",
   "metadata": {},
   "source": [
    "# Explaining MTCNN predictions manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0728a-2aa6-4be5-bb55-c20e3e674af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots(ncols=2, nrows=3)\n",
    "\n",
    "for idx in range(6):\n",
    "    \n",
    "    img, _ = validation_dataset[idx]\n",
    "    output_img = img.copy()\n",
    "    boxes = trainer.predict(img)\n",
    "    \n",
    "    for box in range(len(boxes)):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color=(255,0,0), thickness=2)\n",
    "    ax[idx, 0].imshow(img)\n",
    "    ax[idx, 1].imshow(output_img)\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2da20-bd9f-4dec-8903-5d448a76b7ae",
   "metadata": {},
   "source": [
    "# Measuring speed of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b6c5996-4fec-440c-94ee-545f7d296414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy \n",
    "import gc\n",
    "\n",
    "def flush_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n",
    "    \n",
    "def measure_face_detector_inference_time(\n",
    "    detector: MTCNN,\n",
    "    input_images: list,\n",
    "    total_repetitions: int,\n",
    "    warmup_iters: int,\n",
    "    device: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Measures the approximate\n",
    "    inference time of the face detector\n",
    "    on a given set of input images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    detector: MTCNN face detector\n",
    "    input_images - list of numpy images\n",
    "    total_repetitions - total number of times to repeat measure iteration\n",
    "    warmup_iters - number of iterations for gpu warmup\n",
    "    device - device, used for inference test (usually the one used in production env)\n",
    "    \"\"\"\n",
    "    detector.device = torch.device(device)\n",
    "    data = [torch.from_numpy(img) for img in input_images]\n",
    "    \n",
    "    for _ in range(warmup_iters):\n",
    "        _, _ = detector.detect(data[0].unsqueeze(0).to(device))\n",
    "\n",
    "    if device.startswith(\"cuda\"):\n",
    "        starter = torch.cuda.Event(enable_timing=True)\n",
    "        ender = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "    avg_times = []\n",
    "\n",
    "    data = torch.stack(data).to(device)\n",
    "    \n",
    "    for _ in range(total_repetitions):\n",
    "            \n",
    "        flush_cache()\n",
    "            \n",
    "        if device.startswith(\"cuda\"):\n",
    "            starter.record()\n",
    "            _, _ = detector.detect(data, landmarks=False)\n",
    "            ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            total_time = ender.elapsed_time(starter) / len(input_images)\n",
    "                \n",
    "        elif device.lower() == \"cpu\":\n",
    "            start_time = time.time()\n",
    "            _, _ = detector.detect(data, landmarks=False)\n",
    "            end_time = time.time()\n",
    "            total_time = (end_time - start_time) / len(input_images)\n",
    "                \n",
    "        avg_times.append(total_time)\n",
    "    return numpy.mean(avg_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16f17ab4-3fb4-4d64-8a01-d09ee94ab4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "model = MTCNN(margin=0, min_face_size=100)\n",
    "data = cv2.imread(\"../../test_input_3.jpeg\", cv2.IMREAD_UNCHANGED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de8cdaa1-1b44-45ec-8f3d-00e1185c2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[837.1934204101562, 109.53155517578125, 933.6088256835938,\n",
      "        229.70932006835938],\n",
      "       [386.7955017089844, 125.48906707763672, 467.9786376953125,\n",
      "        246.12094116210938],\n",
      "       [655.2368774414062, 116.82803344726562, 736.0848999023438,\n",
      "        228.511962890625]], dtype=object), array([0.9985974431037903, 0.9821616411209106, 0.9999810457229614],\n",
      "      dtype=object))\n"
     ]
    }
   ],
   "source": [
    "print(model.detect(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1365ae8d-2014-464d-851a-6d32607d3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013583757877349854"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_face_detector_inference_time(model, [data], 100, 10, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8aab54-8486-4458-9663-082322f7a0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08dc505-7a55-4e79-90c2-8cfc8d0921c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
